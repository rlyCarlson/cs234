  6%|█████▋                                                                                                | 50/897 [07:20<2:04:11,  8.80s/it]Traceback (most recent call last):
{'loss': 0.6945, 'grad_norm': 419307.4375, 'learning_rate': 4.944258639910814e-06, 'rewards/chosen': -0.047110624611377716, 'rewards/rejected': -0.046960584819316864, 'rewards/accuracies': 0.503125011920929, 'rewards/margins': -0.00015003979206085205, 'logps/chosen': -100.94339752197266, 'logps/rejected': -102.6556167602539, 'logits/chosen': -1.8037233352661133, 'logits/rejected': -1.7253748178482056, 'epoch': 0.03}
{'loss': 0.7017, 'grad_norm': 249081.75, 'learning_rate': 4.888517279821628e-06, 'rewards/chosen': -0.10632630437612534, 'rewards/rejected': -0.10032837092876434, 'rewards/accuracies': 0.515625, 'rewards/margins': -0.005997927859425545, 'logps/chosen': -104.15409088134766, 'logps/rejected': -99.30511474609375, 'logits/chosen': -1.624704360961914, 'logits/rejected': -1.4874420166015625, 'epoch': 0.07}
{'loss': 0.7055, 'grad_norm': 292492.125, 'learning_rate': 4.832775919732442e-06, 'rewards/chosen': -0.10434728860855103, 'rewards/rejected': -0.09636849910020828, 'rewards/accuracies': 0.48750001192092896, 'rewards/margins': -0.007978786714375019, 'logps/chosen': -110.56494140625, 'logps/rejected': -106.7823257446289, 'logits/chosen': -1.4456855058670044, 'logits/rejected': -1.522218942642212, 'epoch': 0.1}
{'loss': 0.7076, 'grad_norm': 313576.5625, 'learning_rate': 4.777034559643255e-06, 'rewards/chosen': -0.08453782647848129, 'rewards/rejected': -0.06988640129566193, 'rewards/accuracies': 0.47187501192092896, 'rewards/margins': -0.014651427045464516, 'logps/chosen': -101.96293640136719, 'logps/rejected': -103.14212799072266, 'logits/chosen': -1.7926170825958252, 'logits/rejected': -1.7748314142227173, 'epoch': 0.13}
{'loss': 0.7279, 'grad_norm': 299412.90625, 'learning_rate': 4.721293199554069e-06, 'rewards/chosen': -0.07625500112771988, 'rewards/rejected': -0.02426263317465782, 'rewards/accuracies': 0.4437499940395355, 'rewards/margins': -0.05199236422777176, 'logps/chosen': -108.3767318725586, 'logps/rejected': -108.6181411743164, 'logits/chosen': -1.5018044710159302, 'logits/rejected': -1.551295518875122, 'epoch': 0.17}
  File "/home/rileycarlson/cs234/training/dpo.py", line 113, in <module>                                   | 218/1198 [03:02<12:30,  1.31it/s]
    main(args)
  File "/home/rileycarlson/cs234/training/dpo.py", line 92, in main
    trainer.train()
  File "/home/rileycarlson/cs234/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 2241, in train
    return inner_training_loop(
  File "/home/rileycarlson/cs234/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 2612, in _inner_training_loop
    self._maybe_log_save_evaluate(
  File "/home/rileycarlson/cs234/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 3085, in _maybe_log_save_evaluate
    metrics = self._evaluate(trial, ignore_keys_for_eval)
  File "/home/rileycarlson/cs234/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 3039, in _evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
  File "/home/rileycarlson/cs234/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 4105, in evaluate
    output = eval_loop(
  File "/home/rileycarlson/cs234/.venv/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py", line 1502, in evaluation_loop
    initial_output = super().evaluation_loop(
  File "/home/rileycarlson/cs234/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 4299, in evaluation_loop
    losses, logits, labels = self.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)
  File "/home/rileycarlson/cs234/.venv/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py", line 1432, in prediction_step
    loss, metrics = self.get_batch_loss_metrics(model, inputs, train_eval="eval")
  File "/home/rileycarlson/cs234/.venv/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py", line 1291, in get_batch_loss_metrics
    model_output = self.concatenated_forward(model, batch)
  File "/home/rileycarlson/cs234/.venv/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py", line 1193, in concatenated_forward
    outputs = model(input_ids, **model_kwargs)
  File "/home/rileycarlson/cs234/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/rileycarlson/cs234/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/rileycarlson/cs234/.venv/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 193, in forward
    outputs = self.parallel_apply(replicas, inputs, module_kwargs)
  File "/home/rileycarlson/cs234/.venv/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 212, in parallel_apply
    return parallel_apply(
  File "/home/rileycarlson/cs234/.venv/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py", line 118, in parallel_apply
    thread.join()
  File "/opt/conda/lib/python3.10/threading.py", line 1096, in join
    self._wait_for_tstate_lock()
  File "/opt/conda/lib/python3.10/threading.py", line 1116, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt
