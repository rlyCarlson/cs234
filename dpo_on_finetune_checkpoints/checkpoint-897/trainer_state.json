{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.991652754590985,
  "eval_steps": 50,
  "global_step": 897,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0333889816360601,
      "grad_norm": 28218.458984375,
      "learning_rate": 4.944258639910814e-06,
      "logits/chosen": -0.9014186859130859,
      "logits/rejected": -0.7509552836418152,
      "logps/chosen": -89.05362701416016,
      "logps/rejected": -90.40377044677734,
      "loss": 0.8229,
      "rewards/accuracies": 0.49687498807907104,
      "rewards/chosen": 1.1418672800064087,
      "rewards/margins": -0.03635774925351143,
      "rewards/rejected": 1.178225040435791,
      "step": 10
    },
    {
      "epoch": 0.0667779632721202,
      "grad_norm": 25365.046875,
      "learning_rate": 4.888517279821628e-06,
      "logits/chosen": -0.7123235464096069,
      "logits/rejected": -0.6161138415336609,
      "logps/chosen": -91.26274108886719,
      "logps/rejected": -87.63111114501953,
      "loss": 0.7548,
      "rewards/accuracies": 0.546875,
      "rewards/chosen": 1.1828089952468872,
      "rewards/margins": 0.11573608964681625,
      "rewards/rejected": 1.0670727491378784,
      "step": 20
    },
    {
      "epoch": 0.1001669449081803,
      "grad_norm": 31177.755859375,
      "learning_rate": 4.832775919732442e-06,
      "logits/chosen": -0.5592635273933411,
      "logits/rejected": -0.6818472146987915,
      "logps/chosen": -96.93864440917969,
      "logps/rejected": -93.63822174072266,
      "loss": 0.7861,
      "rewards/accuracies": 0.5218750238418579,
      "rewards/chosen": 1.258283019065857,
      "rewards/margins": 0.040239863097667694,
      "rewards/rejected": 1.2180432081222534,
      "step": 30
    },
    {
      "epoch": 0.1335559265442404,
      "grad_norm": 29487.263671875,
      "learning_rate": 4.777034559643255e-06,
      "logits/chosen": -0.9466444253921509,
      "logits/rejected": -0.9174114465713501,
      "logps/chosen": -90.31245422363281,
      "logps/rejected": -91.05643463134766,
      "loss": 0.8296,
      "rewards/accuracies": 0.46562498807907104,
      "rewards/chosen": 1.0805103778839111,
      "rewards/margins": -0.058173131197690964,
      "rewards/rejected": 1.138683557510376,
      "step": 40
    },
    {
      "epoch": 0.1669449081803005,
      "grad_norm": 26953.185546875,
      "learning_rate": 4.721293199554069e-06,
      "logits/chosen": -0.5895161032676697,
      "logits/rejected": -0.6609318852424622,
      "logps/chosen": -95.18807220458984,
      "logps/rejected": -96.13047790527344,
      "loss": 0.7914,
      "rewards/accuracies": 0.4749999940395355,
      "rewards/chosen": 1.2426114082336426,
      "rewards/margins": 0.01810857281088829,
      "rewards/rejected": 1.2245028018951416,
      "step": 50
    },
    {
      "epoch": 0.1669449081803005,
      "eval_logits/chosen": -2.1634981632232666,
      "eval_logits/rejected": -2.17749285697937,
      "eval_logps/chosen": -67.82340240478516,
      "eval_logps/rejected": -69.49179077148438,
      "eval_loss": 0.7976647019386292,
      "eval_rewards/accuracies": 0.48076921701431274,
      "eval_rewards/chosen": 0.9072723984718323,
      "eval_rewards/margins": -0.04182936251163483,
      "eval_rewards/rejected": 0.9491018056869507,
      "eval_runtime": 9.519,
      "eval_samples_per_second": 10.505,
      "eval_steps_per_second": 1.366,
      "step": 50
    },
    {
      "epoch": 0.2003338898163606,
      "grad_norm": 22853.24609375,
      "learning_rate": 4.665551839464883e-06,
      "logits/chosen": -0.7377992868423462,
      "logits/rejected": -0.6462793946266174,
      "logps/chosen": -96.24208068847656,
      "logps/rejected": -95.05780792236328,
      "loss": 0.7604,
      "rewards/accuracies": 0.534375011920929,
      "rewards/chosen": 1.2141162157058716,
      "rewards/margins": 0.05697745829820633,
      "rewards/rejected": 1.157138705253601,
      "step": 60
    },
    {
      "epoch": 0.2337228714524207,
      "grad_norm": 30965.14453125,
      "learning_rate": 4.609810479375697e-06,
      "logits/chosen": -0.6904518008232117,
      "logits/rejected": -0.5400981307029724,
      "logps/chosen": -93.45621490478516,
      "logps/rejected": -98.28437042236328,
      "loss": 0.8712,
      "rewards/accuracies": 0.43437498807907104,
      "rewards/chosen": 1.1638171672821045,
      "rewards/margins": -0.1377500593662262,
      "rewards/rejected": 1.3015674352645874,
      "step": 70
    },
    {
      "epoch": 0.2671118530884808,
      "grad_norm": 29691.740234375,
      "learning_rate": 4.554069119286511e-06,
      "logits/chosen": -0.6853002309799194,
      "logits/rejected": -0.7946156859397888,
      "logps/chosen": -93.04014587402344,
      "logps/rejected": -94.50685119628906,
      "loss": 0.7669,
      "rewards/accuracies": 0.559374988079071,
      "rewards/chosen": 1.2083097696304321,
      "rewards/margins": 0.0700809434056282,
      "rewards/rejected": 1.1382286548614502,
      "step": 80
    },
    {
      "epoch": 0.3005008347245409,
      "grad_norm": 32398.462890625,
      "learning_rate": 4.498327759197324e-06,
      "logits/chosen": -0.7485183477401733,
      "logits/rejected": -0.692169189453125,
      "logps/chosen": -93.36351013183594,
      "logps/rejected": -94.90127563476562,
      "loss": 0.7866,
      "rewards/accuracies": 0.484375,
      "rewards/chosen": 1.1380308866500854,
      "rewards/margins": -0.016969673335552216,
      "rewards/rejected": 1.1550006866455078,
      "step": 90
    },
    {
      "epoch": 0.333889816360601,
      "grad_norm": 23564.1484375,
      "learning_rate": 4.442586399108139e-06,
      "logits/chosen": -0.7279411554336548,
      "logits/rejected": -0.7441531419754028,
      "logps/chosen": -93.99674224853516,
      "logps/rejected": -89.48680877685547,
      "loss": 0.773,
      "rewards/accuracies": 0.5562499761581421,
      "rewards/chosen": 1.2034534215927124,
      "rewards/margins": 0.05516991764307022,
      "rewards/rejected": 1.14828360080719,
      "step": 100
    },
    {
      "epoch": 0.333889816360601,
      "eval_logits/chosen": -2.2328717708587646,
      "eval_logits/rejected": -2.2465338706970215,
      "eval_logps/chosen": -67.95526885986328,
      "eval_logps/rejected": -69.65506744384766,
      "eval_loss": 0.7874148488044739,
      "eval_rewards/accuracies": 0.48076921701431274,
      "eval_rewards/chosen": 0.8940867185592651,
      "eval_rewards/margins": -0.03868788853287697,
      "eval_rewards/rejected": 0.9327746033668518,
      "eval_runtime": 9.4649,
      "eval_samples_per_second": 10.565,
      "eval_steps_per_second": 1.373,
      "step": 100
    },
    {
      "epoch": 0.3672787979966611,
      "grad_norm": 29006.46875,
      "learning_rate": 4.386845039018953e-06,
      "logits/chosen": -0.7433385252952576,
      "logits/rejected": -0.6917708516120911,
      "logps/chosen": -93.07969665527344,
      "logps/rejected": -97.42161560058594,
      "loss": 0.8509,
      "rewards/accuracies": 0.45625001192092896,
      "rewards/chosen": 1.17112135887146,
      "rewards/margins": -0.0998738631606102,
      "rewards/rejected": 1.2709952592849731,
      "step": 110
    },
    {
      "epoch": 0.4006677796327212,
      "grad_norm": 34676.48046875,
      "learning_rate": 4.331103678929766e-06,
      "logits/chosen": -0.8079754710197449,
      "logits/rejected": -0.7308500409126282,
      "logps/chosen": -93.99290466308594,
      "logps/rejected": -93.7492446899414,
      "loss": 0.8488,
      "rewards/accuracies": 0.453125,
      "rewards/chosen": 1.1045725345611572,
      "rewards/margins": -0.09890203922986984,
      "rewards/rejected": 1.2034746408462524,
      "step": 120
    },
    {
      "epoch": 0.4340567612687813,
      "grad_norm": 26262.0390625,
      "learning_rate": 4.27536231884058e-06,
      "logits/chosen": -0.6872631311416626,
      "logits/rejected": -0.7848892211914062,
      "logps/chosen": -93.10606384277344,
      "logps/rejected": -93.65599060058594,
      "loss": 0.7916,
      "rewards/accuracies": 0.48124998807907104,
      "rewards/chosen": 1.2021524906158447,
      "rewards/margins": 0.010246219113469124,
      "rewards/rejected": 1.1919063329696655,
      "step": 130
    },
    {
      "epoch": 0.4674457429048414,
      "grad_norm": 32692.833984375,
      "learning_rate": 4.219620958751394e-06,
      "logits/chosen": -0.9800316095352173,
      "logits/rejected": -1.0793287754058838,
      "logps/chosen": -91.62455749511719,
      "logps/rejected": -90.9510498046875,
      "loss": 0.8047,
      "rewards/accuracies": 0.503125011920929,
      "rewards/chosen": 1.1183604001998901,
      "rewards/margins": -0.009185587987303734,
      "rewards/rejected": 1.1275460720062256,
      "step": 140
    },
    {
      "epoch": 0.5008347245409015,
      "grad_norm": 28204.021484375,
      "learning_rate": 4.163879598662208e-06,
      "logits/chosen": -0.9017506837844849,
      "logits/rejected": -0.875632643699646,
      "logps/chosen": -92.88322448730469,
      "logps/rejected": -91.0998764038086,
      "loss": 0.7641,
      "rewards/accuracies": 0.518750011920929,
      "rewards/chosen": 1.122214913368225,
      "rewards/margins": 0.029957514256238937,
      "rewards/rejected": 1.0922572612762451,
      "step": 150
    },
    {
      "epoch": 0.5008347245409015,
      "eval_logits/chosen": -2.2941157817840576,
      "eval_logits/rejected": -2.307234525680542,
      "eval_logps/chosen": -68.13494110107422,
      "eval_logps/rejected": -69.86080932617188,
      "eval_loss": 0.7786898612976074,
      "eval_rewards/accuracies": 0.48076921701431274,
      "eval_rewards/chosen": 0.8761190176010132,
      "eval_rewards/margins": -0.03608126565814018,
      "eval_rewards/rejected": 0.9122003316879272,
      "eval_runtime": 9.4011,
      "eval_samples_per_second": 10.637,
      "eval_steps_per_second": 1.383,
      "step": 150
    },
    {
      "epoch": 0.5342237061769616,
      "grad_norm": 27109.966796875,
      "learning_rate": 4.108138238573022e-06,
      "logits/chosen": -0.914760947227478,
      "logits/rejected": -0.8942965269088745,
      "logps/chosen": -96.50455474853516,
      "logps/rejected": -93.38882446289062,
      "loss": 0.7869,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": 1.1181509494781494,
      "rewards/margins": 0.009429613128304482,
      "rewards/rejected": 1.1087214946746826,
      "step": 160
    },
    {
      "epoch": 0.5676126878130217,
      "grad_norm": 26486.958984375,
      "learning_rate": 4.052396878483836e-06,
      "logits/chosen": -1.177152156829834,
      "logits/rejected": -1.1179741621017456,
      "logps/chosen": -89.9749526977539,
      "logps/rejected": -90.68778991699219,
      "loss": 0.8048,
      "rewards/accuracies": 0.49687498807907104,
      "rewards/chosen": 1.010307788848877,
      "rewards/margins": -0.04688252881169319,
      "rewards/rejected": 1.0571902990341187,
      "step": 170
    },
    {
      "epoch": 0.6010016694490818,
      "grad_norm": 24963.8203125,
      "learning_rate": 3.99665551839465e-06,
      "logits/chosen": -0.9192411303520203,
      "logits/rejected": -0.8567116856575012,
      "logps/chosen": -94.54801940917969,
      "logps/rejected": -96.40935516357422,
      "loss": 0.8101,
      "rewards/accuracies": 0.503125011920929,
      "rewards/chosen": 1.086181879043579,
      "rewards/margins": -0.04505572468042374,
      "rewards/rejected": 1.1312377452850342,
      "step": 180
    },
    {
      "epoch": 0.6343906510851419,
      "grad_norm": 34927.140625,
      "learning_rate": 3.940914158305463e-06,
      "logits/chosen": -0.8770748376846313,
      "logits/rejected": -0.8924598693847656,
      "logps/chosen": -95.45915222167969,
      "logps/rejected": -93.27601623535156,
      "loss": 0.7691,
      "rewards/accuracies": 0.528124988079071,
      "rewards/chosen": 1.1307003498077393,
      "rewards/margins": 0.031361453235149384,
      "rewards/rejected": 1.0993388891220093,
      "step": 190
    },
    {
      "epoch": 0.667779632721202,
      "grad_norm": 32520.005859375,
      "learning_rate": 3.885172798216277e-06,
      "logits/chosen": -1.057647466659546,
      "logits/rejected": -1.0302549600601196,
      "logps/chosen": -93.81900787353516,
      "logps/rejected": -96.02164459228516,
      "loss": 0.7931,
      "rewards/accuracies": 0.45625001192092896,
      "rewards/chosen": 1.1055548191070557,
      "rewards/margins": -0.05312337353825569,
      "rewards/rejected": 1.1586781740188599,
      "step": 200
    },
    {
      "epoch": 0.667779632721202,
      "eval_logits/chosen": -2.3458240032196045,
      "eval_logits/rejected": -2.358786106109619,
      "eval_logps/chosen": -68.48021697998047,
      "eval_logps/rejected": -70.21953582763672,
      "eval_loss": 0.7733517289161682,
      "eval_rewards/accuracies": 0.48076921701431274,
      "eval_rewards/chosen": 0.8415908813476562,
      "eval_rewards/margins": -0.03473639860749245,
      "eval_rewards/rejected": 0.876327395439148,
      "eval_runtime": 9.4221,
      "eval_samples_per_second": 10.613,
      "eval_steps_per_second": 1.38,
      "step": 200
    },
    {
      "epoch": 0.7011686143572621,
      "grad_norm": 28290.576171875,
      "learning_rate": 3.8294314381270906e-06,
      "logits/chosen": -0.9138081669807434,
      "logits/rejected": -0.8814871907234192,
      "logps/chosen": -92.49360656738281,
      "logps/rejected": -96.60160827636719,
      "loss": 0.8052,
      "rewards/accuracies": 0.45625001192092896,
      "rewards/chosen": 1.0595080852508545,
      "rewards/margins": -0.06888312846422195,
      "rewards/rejected": 1.1283913850784302,
      "step": 210
    },
    {
      "epoch": 0.7345575959933222,
      "grad_norm": 31414.33984375,
      "learning_rate": 3.7736900780379045e-06,
      "logits/chosen": -0.9207698702812195,
      "logits/rejected": -1.057752251625061,
      "logps/chosen": -94.1361312866211,
      "logps/rejected": -93.70069885253906,
      "loss": 0.7859,
      "rewards/accuracies": 0.484375,
      "rewards/chosen": 1.0581152439117432,
      "rewards/margins": -0.008141344413161278,
      "rewards/rejected": 1.0662564039230347,
      "step": 220
    },
    {
      "epoch": 0.7679465776293823,
      "grad_norm": 28942.556640625,
      "learning_rate": 3.7179487179487184e-06,
      "logits/chosen": -0.9358406066894531,
      "logits/rejected": -0.9716243743896484,
      "logps/chosen": -92.63993072509766,
      "logps/rejected": -93.40409851074219,
      "loss": 0.7959,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": 1.1109340190887451,
      "rewards/margins": 0.0009184583905152977,
      "rewards/rejected": 1.1100155115127563,
      "step": 230
    },
    {
      "epoch": 0.8013355592654424,
      "grad_norm": 24138.875,
      "learning_rate": 3.662207357859532e-06,
      "logits/chosen": -0.8019957542419434,
      "logits/rejected": -0.8378576040267944,
      "logps/chosen": -95.9653549194336,
      "logps/rejected": -96.42478942871094,
      "loss": 0.7756,
      "rewards/accuracies": 0.4906249940395355,
      "rewards/chosen": 1.124315619468689,
      "rewards/margins": 0.005164601840078831,
      "rewards/rejected": 1.119150996208191,
      "step": 240
    },
    {
      "epoch": 0.8347245409015025,
      "grad_norm": 33847.07421875,
      "learning_rate": 3.606465997770346e-06,
      "logits/chosen": -1.0464503765106201,
      "logits/rejected": -1.0296461582183838,
      "logps/chosen": -92.97752380371094,
      "logps/rejected": -91.87236022949219,
      "loss": 0.7469,
      "rewards/accuracies": 0.4781250059604645,
      "rewards/chosen": 1.0665748119354248,
      "rewards/margins": 0.05023053288459778,
      "rewards/rejected": 1.0163443088531494,
      "step": 250
    },
    {
      "epoch": 0.8347245409015025,
      "eval_logits/chosen": -2.3996946811676025,
      "eval_logits/rejected": -2.4126665592193604,
      "eval_logps/chosen": -68.74925231933594,
      "eval_logps/rejected": -70.50358581542969,
      "eval_loss": 0.7678465247154236,
      "eval_rewards/accuracies": 0.48076921701431274,
      "eval_rewards/chosen": 0.8146883845329285,
      "eval_rewards/margins": -0.033234238624572754,
      "eval_rewards/rejected": 0.8479226231575012,
      "eval_runtime": 9.2188,
      "eval_samples_per_second": 10.847,
      "eval_steps_per_second": 1.41,
      "step": 250
    },
    {
      "epoch": 0.8681135225375626,
      "grad_norm": 26119.30078125,
      "learning_rate": 3.55072463768116e-06,
      "logits/chosen": -1.1168315410614014,
      "logits/rejected": -1.0781618356704712,
      "logps/chosen": -93.82438659667969,
      "logps/rejected": -91.75965881347656,
      "loss": 0.7396,
      "rewards/accuracies": 0.5406249761581421,
      "rewards/chosen": 1.1103098392486572,
      "rewards/margins": 0.12066688388586044,
      "rewards/rejected": 0.9896427989006042,
      "step": 260
    },
    {
      "epoch": 0.9015025041736227,
      "grad_norm": 25659.197265625,
      "learning_rate": 3.4949832775919733e-06,
      "logits/chosen": -0.9546879529953003,
      "logits/rejected": -0.900484561920166,
      "logps/chosen": -96.07867431640625,
      "logps/rejected": -96.14092254638672,
      "loss": 0.8028,
      "rewards/accuracies": 0.484375,
      "rewards/chosen": 1.1073211431503296,
      "rewards/margins": -0.025132913142442703,
      "rewards/rejected": 1.1324541568756104,
      "step": 270
    },
    {
      "epoch": 0.9348914858096828,
      "grad_norm": 25324.4765625,
      "learning_rate": 3.4392419175027873e-06,
      "logits/chosen": -1.0096877813339233,
      "logits/rejected": -1.1038247346878052,
      "logps/chosen": -90.70308685302734,
      "logps/rejected": -94.2024917602539,
      "loss": 0.7659,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 0.9897805452346802,
      "rewards/margins": 0.023186232894659042,
      "rewards/rejected": 0.9665943384170532,
      "step": 280
    },
    {
      "epoch": 0.9682804674457429,
      "grad_norm": 26697.4375,
      "learning_rate": 3.3835005574136008e-06,
      "logits/chosen": -0.7964667677879333,
      "logits/rejected": -0.9730997085571289,
      "logps/chosen": -94.67487335205078,
      "logps/rejected": -91.93790435791016,
      "loss": 0.7754,
      "rewards/accuracies": 0.4937500059604645,
      "rewards/chosen": 1.0063972473144531,
      "rewards/margins": -0.006280435714870691,
      "rewards/rejected": 1.012677788734436,
      "step": 290
    },
    {
      "epoch": 1.0,
      "grad_norm": 24805.521484375,
      "learning_rate": 3.327759197324415e-06,
      "logits/chosen": -1.0097099542617798,
      "logits/rejected": -0.9553257822990417,
      "logps/chosen": -96.9124984741211,
      "logps/rejected": -92.91402435302734,
      "loss": 0.732,
      "rewards/accuracies": 0.48245611786842346,
      "rewards/chosen": 1.0493226051330566,
      "rewards/margins": -0.0005496128578670323,
      "rewards/rejected": 1.0498721599578857,
      "step": 300
    },
    {
      "epoch": 1.0,
      "eval_logits/chosen": -2.4235072135925293,
      "eval_logits/rejected": -2.436262369155884,
      "eval_logps/chosen": -68.9182357788086,
      "eval_logps/rejected": -70.68995666503906,
      "eval_loss": 0.763261616230011,
      "eval_rewards/accuracies": 0.48076921701431274,
      "eval_rewards/chosen": 0.7977896332740784,
      "eval_rewards/margins": -0.031495410948991776,
      "eval_rewards/rejected": 0.829285204410553,
      "eval_runtime": 9.4949,
      "eval_samples_per_second": 10.532,
      "eval_steps_per_second": 1.369,
      "step": 300
    },
    {
      "epoch": 1.0333889816360602,
      "grad_norm": 23147.04296875,
      "learning_rate": 3.272017837235229e-06,
      "logits/chosen": -0.9452669024467468,
      "logits/rejected": -0.8419134020805359,
      "logps/chosen": -98.4549789428711,
      "logps/rejected": -94.6779556274414,
      "loss": 0.7389,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 1.0936319828033447,
      "rewards/margins": 0.06439577788114548,
      "rewards/rejected": 1.029236078262329,
      "step": 310
    },
    {
      "epoch": 1.0667779632721202,
      "grad_norm": 25148.90234375,
      "learning_rate": 3.2162764771460426e-06,
      "logits/chosen": -0.8821120262145996,
      "logits/rejected": -1.0118590593338013,
      "logps/chosen": -95.18547058105469,
      "logps/rejected": -95.7166976928711,
      "loss": 0.7822,
      "rewards/accuracies": 0.46875,
      "rewards/chosen": 1.0119860172271729,
      "rewards/margins": -0.008548879995942116,
      "rewards/rejected": 1.020534873008728,
      "step": 320
    },
    {
      "epoch": 1.1001669449081803,
      "grad_norm": 29120.591796875,
      "learning_rate": 3.1605351170568565e-06,
      "logits/chosen": -1.1009631156921387,
      "logits/rejected": -1.2423148155212402,
      "logps/chosen": -89.84138488769531,
      "logps/rejected": -90.12879943847656,
      "loss": 0.8088,
      "rewards/accuracies": 0.4625000059604645,
      "rewards/chosen": 0.9779165983200073,
      "rewards/margins": -0.05891743302345276,
      "rewards/rejected": 1.0368340015411377,
      "step": 330
    },
    {
      "epoch": 1.1335559265442403,
      "grad_norm": 25503.08203125,
      "learning_rate": 3.10479375696767e-06,
      "logits/chosen": -1.2844676971435547,
      "logits/rejected": -1.228689432144165,
      "logps/chosen": -89.93941497802734,
      "logps/rejected": -90.95994567871094,
      "loss": 0.7769,
      "rewards/accuracies": 0.4906249940395355,
      "rewards/chosen": 0.949853777885437,
      "rewards/margins": -0.024111870676279068,
      "rewards/rejected": 0.9739656448364258,
      "step": 340
    },
    {
      "epoch": 1.1669449081803005,
      "grad_norm": 28355.8046875,
      "learning_rate": 3.049052396878484e-06,
      "logits/chosen": -1.178369164466858,
      "logits/rejected": -1.083434820175171,
      "logps/chosen": -93.56343841552734,
      "logps/rejected": -96.46232604980469,
      "loss": 0.789,
      "rewards/accuracies": 0.5218750238418579,
      "rewards/chosen": 1.0191701650619507,
      "rewards/margins": -0.03174244612455368,
      "rewards/rejected": 1.050912618637085,
      "step": 350
    },
    {
      "epoch": 1.1669449081803005,
      "eval_logits/chosen": -2.4495179653167725,
      "eval_logits/rejected": -2.462228536605835,
      "eval_logps/chosen": -69.18484497070312,
      "eval_logps/rejected": -70.97039031982422,
      "eval_loss": 0.7594086527824402,
      "eval_rewards/accuracies": 0.48076921701431274,
      "eval_rewards/chosen": 0.7711284160614014,
      "eval_rewards/margins": -0.030112918466329575,
      "eval_rewards/rejected": 0.8012414574623108,
      "eval_runtime": 9.3087,
      "eval_samples_per_second": 10.743,
      "eval_steps_per_second": 1.397,
      "step": 350
    },
    {
      "epoch": 1.2003338898163607,
      "grad_norm": 29597.35546875,
      "learning_rate": 2.9933110367892983e-06,
      "logits/chosen": -0.8378931879997253,
      "logits/rejected": -0.943069577217102,
      "logps/chosen": -93.4332275390625,
      "logps/rejected": -95.60372924804688,
      "loss": 0.7553,
      "rewards/accuracies": 0.49687498807907104,
      "rewards/chosen": 1.0201829671859741,
      "rewards/margins": 0.015344003215432167,
      "rewards/rejected": 1.0048391819000244,
      "step": 360
    },
    {
      "epoch": 1.2337228714524207,
      "grad_norm": 27912.08984375,
      "learning_rate": 2.9375696767001114e-06,
      "logits/chosen": -0.901897132396698,
      "logits/rejected": -0.8625532388687134,
      "logps/chosen": -94.57312774658203,
      "logps/rejected": -96.64253997802734,
      "loss": 0.7752,
      "rewards/accuracies": 0.4749999940395355,
      "rewards/chosen": 1.0244817733764648,
      "rewards/margins": -0.033299900591373444,
      "rewards/rejected": 1.05778169631958,
      "step": 370
    },
    {
      "epoch": 1.2671118530884808,
      "grad_norm": 36203.140625,
      "learning_rate": 2.881828316610926e-06,
      "logits/chosen": -1.2528704404830933,
      "logits/rejected": -1.2712185382843018,
      "logps/chosen": -92.32150268554688,
      "logps/rejected": -91.44224548339844,
      "loss": 0.7594,
      "rewards/accuracies": 0.47187501192092896,
      "rewards/chosen": 0.9612294435501099,
      "rewards/margins": -0.006885322742164135,
      "rewards/rejected": 0.9681148529052734,
      "step": 380
    },
    {
      "epoch": 1.300500834724541,
      "grad_norm": 25808.85546875,
      "learning_rate": 2.8260869565217393e-06,
      "logits/chosen": -1.3306232690811157,
      "logits/rejected": -1.191127061843872,
      "logps/chosen": -93.19930267333984,
      "logps/rejected": -89.47307586669922,
      "loss": 0.7347,
      "rewards/accuracies": 0.5531250238418579,
      "rewards/chosen": 0.9951637387275696,
      "rewards/margins": 0.04835420474410057,
      "rewards/rejected": 0.9468094110488892,
      "step": 390
    },
    {
      "epoch": 1.333889816360601,
      "grad_norm": 29513.03125,
      "learning_rate": 2.7703455964325532e-06,
      "logits/chosen": -0.7901932001113892,
      "logits/rejected": -0.915960967540741,
      "logps/chosen": -97.26234436035156,
      "logps/rejected": -95.9455795288086,
      "loss": 0.7565,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 1.007575273513794,
      "rewards/margins": -0.0010706990724429488,
      "rewards/rejected": 1.0086461305618286,
      "step": 400
    },
    {
      "epoch": 1.333889816360601,
      "eval_logits/chosen": -2.4768121242523193,
      "eval_logits/rejected": -2.4894776344299316,
      "eval_logps/chosen": -69.30480194091797,
      "eval_logps/rejected": -71.09734344482422,
      "eval_loss": 0.7567903995513916,
      "eval_rewards/accuracies": 0.48076921701431274,
      "eval_rewards/chosen": 0.7591330409049988,
      "eval_rewards/margins": -0.02941281907260418,
      "eval_rewards/rejected": 0.7885459065437317,
      "eval_runtime": 9.3794,
      "eval_samples_per_second": 10.662,
      "eval_steps_per_second": 1.386,
      "step": 400
    },
    {
      "epoch": 1.367278797996661,
      "grad_norm": 25340.876953125,
      "learning_rate": 2.714604236343367e-06,
      "logits/chosen": -1.106563925743103,
      "logits/rejected": -1.0907772779464722,
      "logps/chosen": -96.35896301269531,
      "logps/rejected": -96.22206115722656,
      "loss": 0.7784,
      "rewards/accuracies": 0.4937500059604645,
      "rewards/chosen": 1.0422499179840088,
      "rewards/margins": 0.003193739103153348,
      "rewards/rejected": 1.039056420326233,
      "step": 410
    },
    {
      "epoch": 1.4006677796327212,
      "grad_norm": 21630.419921875,
      "learning_rate": 2.6588628762541807e-06,
      "logits/chosen": -0.9587804675102234,
      "logits/rejected": -1.0130834579467773,
      "logps/chosen": -93.58160400390625,
      "logps/rejected": -92.93888854980469,
      "loss": 0.7298,
      "rewards/accuracies": 0.53125,
      "rewards/chosen": 1.010105848312378,
      "rewards/margins": 0.05636810511350632,
      "rewards/rejected": 0.9537376165390015,
      "step": 420
    },
    {
      "epoch": 1.4340567612687813,
      "grad_norm": 23237.365234375,
      "learning_rate": 2.6031215161649946e-06,
      "logits/chosen": -1.052257776260376,
      "logits/rejected": -0.9744798541069031,
      "logps/chosen": -95.05613708496094,
      "logps/rejected": -93.06585693359375,
      "loss": 0.7639,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 0.9650022387504578,
      "rewards/margins": -0.009674305096268654,
      "rewards/rejected": 0.9746764898300171,
      "step": 430
    },
    {
      "epoch": 1.4674457429048413,
      "grad_norm": 29058.638671875,
      "learning_rate": 2.547380156075808e-06,
      "logits/chosen": -1.0847423076629639,
      "logits/rejected": -0.9538812637329102,
      "logps/chosen": -95.7462387084961,
      "logps/rejected": -94.3337631225586,
      "loss": 0.7547,
      "rewards/accuracies": 0.5062500238418579,
      "rewards/chosen": 0.976739764213562,
      "rewards/margins": 0.017418434843420982,
      "rewards/rejected": 0.9593213796615601,
      "step": 440
    },
    {
      "epoch": 1.5008347245409015,
      "grad_norm": 23591.42578125,
      "learning_rate": 2.491638795986622e-06,
      "logits/chosen": -0.9802262187004089,
      "logits/rejected": -1.0114718675613403,
      "logps/chosen": -94.72795867919922,
      "logps/rejected": -97.42597961425781,
      "loss": 0.7945,
      "rewards/accuracies": 0.43437498807907104,
      "rewards/chosen": 1.0578665733337402,
      "rewards/margins": -0.050506509840488434,
      "rewards/rejected": 1.1083731651306152,
      "step": 450
    },
    {
      "epoch": 1.5008347245409015,
      "eval_logits/chosen": -2.5007400512695312,
      "eval_logits/rejected": -2.5132904052734375,
      "eval_logps/chosen": -69.42308044433594,
      "eval_logps/rejected": -71.22501373291016,
      "eval_loss": 0.7546169757843018,
      "eval_rewards/accuracies": 0.48076921701431274,
      "eval_rewards/chosen": 0.7473053336143494,
      "eval_rewards/margins": -0.02847430296242237,
      "eval_rewards/rejected": 0.775779664516449,
      "eval_runtime": 9.2583,
      "eval_samples_per_second": 10.801,
      "eval_steps_per_second": 1.404,
      "step": 450
    },
    {
      "epoch": 1.5342237061769617,
      "grad_norm": 27923.283203125,
      "learning_rate": 2.435897435897436e-06,
      "logits/chosen": -1.070304274559021,
      "logits/rejected": -1.0779496431350708,
      "logps/chosen": -96.71347045898438,
      "logps/rejected": -97.97284698486328,
      "loss": 0.7721,
      "rewards/accuracies": 0.503125011920929,
      "rewards/chosen": 1.0280559062957764,
      "rewards/margins": -0.010994449257850647,
      "rewards/rejected": 1.0390504598617554,
      "step": 460
    },
    {
      "epoch": 1.5676126878130217,
      "grad_norm": 25735.1875,
      "learning_rate": 2.38015607580825e-06,
      "logits/chosen": -1.2706577777862549,
      "logits/rejected": -1.1315523386001587,
      "logps/chosen": -90.55709075927734,
      "logps/rejected": -93.7469711303711,
      "loss": 0.7625,
      "rewards/accuracies": 0.528124988079071,
      "rewards/chosen": 0.9469858407974243,
      "rewards/margins": -0.007224960718303919,
      "rewards/rejected": 0.9542107582092285,
      "step": 470
    },
    {
      "epoch": 1.6010016694490818,
      "grad_norm": 27020.1328125,
      "learning_rate": 2.324414715719064e-06,
      "logits/chosen": -1.0620901584625244,
      "logits/rejected": -1.225120186805725,
      "logps/chosen": -92.47858428955078,
      "logps/rejected": -89.18663024902344,
      "loss": 0.7489,
      "rewards/accuracies": 0.5093749761581421,
      "rewards/chosen": 0.9669978022575378,
      "rewards/margins": 0.040433358401060104,
      "rewards/rejected": 0.9265645146369934,
      "step": 480
    },
    {
      "epoch": 1.634390651085142,
      "grad_norm": 25143.240234375,
      "learning_rate": 2.2686733556298774e-06,
      "logits/chosen": -1.0495206117630005,
      "logits/rejected": -1.0745512247085571,
      "logps/chosen": -95.63353729248047,
      "logps/rejected": -98.33956146240234,
      "loss": 0.8028,
      "rewards/accuracies": 0.4468750059604645,
      "rewards/chosen": 0.9840246438980103,
      "rewards/margins": -0.06352296471595764,
      "rewards/rejected": 1.0475475788116455,
      "step": 490
    },
    {
      "epoch": 1.667779632721202,
      "grad_norm": 29837.0,
      "learning_rate": 2.2129319955406913e-06,
      "logits/chosen": -1.0452771186828613,
      "logits/rejected": -1.0833684206008911,
      "logps/chosen": -97.35852813720703,
      "logps/rejected": -97.70352935791016,
      "loss": 0.7503,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 1.0292917490005493,
      "rewards/margins": 0.02167624607682228,
      "rewards/rejected": 1.0076154470443726,
      "step": 500
    },
    {
      "epoch": 1.667779632721202,
      "eval_logits/chosen": -2.5298566818237305,
      "eval_logits/rejected": -2.542429208755493,
      "eval_logps/chosen": -69.59337615966797,
      "eval_logps/rejected": -71.40226745605469,
      "eval_loss": 0.7523327469825745,
      "eval_rewards/accuracies": 0.48076921701431274,
      "eval_rewards/chosen": 0.7302756905555725,
      "eval_rewards/margins": -0.02777840569615364,
      "eval_rewards/rejected": 0.7580540776252747,
      "eval_runtime": 9.3147,
      "eval_samples_per_second": 10.736,
      "eval_steps_per_second": 1.396,
      "step": 500
    },
    {
      "epoch": 1.701168614357262,
      "grad_norm": 21877.30859375,
      "learning_rate": 2.1571906354515053e-06,
      "logits/chosen": -1.092331051826477,
      "logits/rejected": -1.2128684520721436,
      "logps/chosen": -96.85323333740234,
      "logps/rejected": -93.11871337890625,
      "loss": 0.7629,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 0.9356477856636047,
      "rewards/margins": -0.011172851547598839,
      "rewards/rejected": 0.9468205571174622,
      "step": 510
    },
    {
      "epoch": 1.7345575959933222,
      "grad_norm": 22797.34375,
      "learning_rate": 2.101449275362319e-06,
      "logits/chosen": -1.1732171773910522,
      "logits/rejected": -1.2161273956298828,
      "logps/chosen": -96.17399597167969,
      "logps/rejected": -92.3834228515625,
      "loss": 0.728,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": 0.9440109133720398,
      "rewards/margins": 0.04847719520330429,
      "rewards/rejected": 0.8955337405204773,
      "step": 520
    },
    {
      "epoch": 1.7679465776293823,
      "grad_norm": 26530.701171875,
      "learning_rate": 2.045707915273133e-06,
      "logits/chosen": -1.1840866804122925,
      "logits/rejected": -1.0370328426361084,
      "logps/chosen": -96.4549331665039,
      "logps/rejected": -100.91633605957031,
      "loss": 0.7739,
      "rewards/accuracies": 0.4468750059604645,
      "rewards/chosen": 0.9784783124923706,
      "rewards/margins": -0.04459162801504135,
      "rewards/rejected": 1.0230698585510254,
      "step": 530
    },
    {
      "epoch": 1.8013355592654423,
      "grad_norm": 29282.369140625,
      "learning_rate": 1.9899665551839467e-06,
      "logits/chosen": -1.2114008665084839,
      "logits/rejected": -1.0397098064422607,
      "logps/chosen": -94.30342102050781,
      "logps/rejected": -95.01349639892578,
      "loss": 0.7689,
      "rewards/accuracies": 0.5093749761581421,
      "rewards/chosen": 0.9068592190742493,
      "rewards/margins": -0.012199370190501213,
      "rewards/rejected": 0.9190585017204285,
      "step": 540
    },
    {
      "epoch": 1.8347245409015025,
      "grad_norm": 22427.318359375,
      "learning_rate": 1.9342251950947606e-06,
      "logits/chosen": -1.0886975526809692,
      "logits/rejected": -1.083194375038147,
      "logps/chosen": -95.44322204589844,
      "logps/rejected": -95.6194076538086,
      "loss": 0.7312,
      "rewards/accuracies": 0.515625,
      "rewards/chosen": 0.9504581689834595,
      "rewards/margins": 0.031045377254486084,
      "rewards/rejected": 0.9194127917289734,
      "step": 550
    },
    {
      "epoch": 1.8347245409015025,
      "eval_logits/chosen": -2.551286220550537,
      "eval_logits/rejected": -2.563886880874634,
      "eval_logps/chosen": -69.74183654785156,
      "eval_logps/rejected": -71.55323791503906,
      "eval_loss": 0.750968873500824,
      "eval_rewards/accuracies": 0.48076921701431274,
      "eval_rewards/chosen": 0.7154296040534973,
      "eval_rewards/margins": -0.02752697840332985,
      "eval_rewards/rejected": 0.7429566979408264,
      "eval_runtime": 9.3046,
      "eval_samples_per_second": 10.747,
      "eval_steps_per_second": 1.397,
      "step": 550
    },
    {
      "epoch": 1.8681135225375627,
      "grad_norm": 21211.232421875,
      "learning_rate": 1.8784838350055743e-06,
      "logits/chosen": -1.0710885524749756,
      "logits/rejected": -1.1675941944122314,
      "logps/chosen": -92.74584197998047,
      "logps/rejected": -93.72003173828125,
      "loss": 0.7833,
      "rewards/accuracies": 0.45625001192092896,
      "rewards/chosen": 0.8890606164932251,
      "rewards/margins": -0.04727017879486084,
      "rewards/rejected": 0.9363309144973755,
      "step": 560
    },
    {
      "epoch": 1.9015025041736227,
      "grad_norm": 26535.41796875,
      "learning_rate": 1.822742474916388e-06,
      "logits/chosen": -1.253357172012329,
      "logits/rejected": -1.210858941078186,
      "logps/chosen": -95.07905578613281,
      "logps/rejected": -93.87849426269531,
      "loss": 0.7211,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.9389840960502625,
      "rewards/margins": 0.05262034013867378,
      "rewards/rejected": 0.886363685131073,
      "step": 570
    },
    {
      "epoch": 1.9348914858096828,
      "grad_norm": 30937.021484375,
      "learning_rate": 1.767001114827202e-06,
      "logits/chosen": -1.006157636642456,
      "logits/rejected": -0.737639307975769,
      "logps/chosen": -100.12382507324219,
      "logps/rejected": -101.91909790039062,
      "loss": 0.8025,
      "rewards/accuracies": 0.5093749761581421,
      "rewards/chosen": 0.9683648347854614,
      "rewards/margins": -0.04931556060910225,
      "rewards/rejected": 1.0176804065704346,
      "step": 580
    },
    {
      "epoch": 1.968280467445743,
      "grad_norm": 21632.015625,
      "learning_rate": 1.7112597547380157e-06,
      "logits/chosen": -0.9896013140678406,
      "logits/rejected": -1.003309965133667,
      "logps/chosen": -102.34654235839844,
      "logps/rejected": -97.786376953125,
      "loss": 0.7389,
      "rewards/accuracies": 0.5062500238418579,
      "rewards/chosen": 1.0197718143463135,
      "rewards/margins": 0.02169090509414673,
      "rewards/rejected": 0.998080849647522,
      "step": 590
    },
    {
      "epoch": 2.0,
      "grad_norm": 19567.826171875,
      "learning_rate": 1.6555183946488297e-06,
      "logits/chosen": -1.107678771018982,
      "logits/rejected": -1.1513841152191162,
      "logps/chosen": -93.59333038330078,
      "logps/rejected": -96.32682800292969,
      "loss": 0.7181,
      "rewards/accuracies": 0.5208333730697632,
      "rewards/chosen": 0.9813923835754395,
      "rewards/margins": 0.014045797288417816,
      "rewards/rejected": 0.9673466086387634,
      "step": 600
    },
    {
      "epoch": 2.0,
      "eval_logits/chosen": -2.5675549507141113,
      "eval_logits/rejected": -2.580190420150757,
      "eval_logps/chosen": -69.83618927001953,
      "eval_logps/rejected": -71.65220642089844,
      "eval_loss": 0.7497967481613159,
      "eval_rewards/accuracies": 0.48076921701431274,
      "eval_rewards/chosen": 0.7059937715530396,
      "eval_rewards/margins": -0.027066418901085854,
      "eval_rewards/rejected": 0.7330602407455444,
      "eval_runtime": 9.2688,
      "eval_samples_per_second": 10.789,
      "eval_steps_per_second": 1.403,
      "step": 600
    },
    {
      "epoch": 2.03338898163606,
      "grad_norm": 28959.865234375,
      "learning_rate": 1.5997770345596434e-06,
      "logits/chosen": -1.2731777429580688,
      "logits/rejected": -1.1163511276245117,
      "logps/chosen": -95.65472412109375,
      "logps/rejected": -96.8799057006836,
      "loss": 0.7552,
      "rewards/accuracies": 0.4937500059604645,
      "rewards/chosen": 0.9570501446723938,
      "rewards/margins": 0.0033262870274484158,
      "rewards/rejected": 0.9537237286567688,
      "step": 610
    },
    {
      "epoch": 2.0667779632721204,
      "grad_norm": 25807.51171875,
      "learning_rate": 1.5440356744704571e-06,
      "logits/chosen": -1.0199860334396362,
      "logits/rejected": -1.037295937538147,
      "logps/chosen": -99.74333953857422,
      "logps/rejected": -100.12762451171875,
      "loss": 0.7647,
      "rewards/accuracies": 0.4937500059604645,
      "rewards/chosen": 1.0116453170776367,
      "rewards/margins": -0.007801990024745464,
      "rewards/rejected": 1.0194473266601562,
      "step": 620
    },
    {
      "epoch": 2.1001669449081803,
      "grad_norm": 31008.88671875,
      "learning_rate": 1.488294314381271e-06,
      "logits/chosen": -1.0980620384216309,
      "logits/rejected": -1.1197104454040527,
      "logps/chosen": -95.3601303100586,
      "logps/rejected": -93.85397338867188,
      "loss": 0.7523,
      "rewards/accuracies": 0.49687498807907104,
      "rewards/chosen": 0.9341109395027161,
      "rewards/margins": 0.0068334490060806274,
      "rewards/rejected": 0.9272773861885071,
      "step": 630
    },
    {
      "epoch": 2.1335559265442403,
      "grad_norm": 26920.92578125,
      "learning_rate": 1.432552954292085e-06,
      "logits/chosen": -1.3474925756454468,
      "logits/rejected": -1.1998591423034668,
      "logps/chosen": -88.57762145996094,
      "logps/rejected": -89.6668930053711,
      "loss": 0.765,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 0.8677967190742493,
      "rewards/margins": -0.03387698531150818,
      "rewards/rejected": 0.9016736745834351,
      "step": 640
    },
    {
      "epoch": 2.1669449081803007,
      "grad_norm": 30375.310546875,
      "learning_rate": 1.3768115942028987e-06,
      "logits/chosen": -1.2563974857330322,
      "logits/rejected": -1.2812579870224,
      "logps/chosen": -93.93038177490234,
      "logps/rejected": -93.04803466796875,
      "loss": 0.7516,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.9210759401321411,
      "rewards/margins": 0.0038916394114494324,
      "rewards/rejected": 0.9171843528747559,
      "step": 650
    },
    {
      "epoch": 2.1669449081803007,
      "eval_logits/chosen": -2.586120128631592,
      "eval_logits/rejected": -2.5987842082977295,
      "eval_logps/chosen": -69.91858673095703,
      "eval_logps/rejected": -71.73757934570312,
      "eval_loss": 0.7486864328384399,
      "eval_rewards/accuracies": 0.48076921701431274,
      "eval_rewards/chosen": 0.6977539658546448,
      "eval_rewards/margins": -0.026769505813717842,
      "eval_rewards/rejected": 0.7245234847068787,
      "eval_runtime": 9.2322,
      "eval_samples_per_second": 10.832,
      "eval_steps_per_second": 1.408,
      "step": 650
    },
    {
      "epoch": 2.2003338898163607,
      "grad_norm": 42799.49609375,
      "learning_rate": 1.3210702341137124e-06,
      "logits/chosen": -1.0902906656265259,
      "logits/rejected": -1.2570643424987793,
      "logps/chosen": -94.83424377441406,
      "logps/rejected": -93.87715148925781,
      "loss": 0.7429,
      "rewards/accuracies": 0.5218750238418579,
      "rewards/chosen": 0.9365673065185547,
      "rewards/margins": 0.020276019349694252,
      "rewards/rejected": 0.916291356086731,
      "step": 660
    },
    {
      "epoch": 2.2337228714524207,
      "grad_norm": 31673.0859375,
      "learning_rate": 1.2653288740245262e-06,
      "logits/chosen": -0.9721144437789917,
      "logits/rejected": -1.0058053731918335,
      "logps/chosen": -98.77226257324219,
      "logps/rejected": -105.33760070800781,
      "loss": 0.7801,
      "rewards/accuracies": 0.44999998807907104,
      "rewards/chosen": 0.9863284826278687,
      "rewards/margins": -0.03623935580253601,
      "rewards/rejected": 1.022567868232727,
      "step": 670
    },
    {
      "epoch": 2.2671118530884806,
      "grad_norm": 25893.603515625,
      "learning_rate": 1.20958751393534e-06,
      "logits/chosen": -1.2821582555770874,
      "logits/rejected": -1.2164406776428223,
      "logps/chosen": -94.26255798339844,
      "logps/rejected": -94.58309936523438,
      "loss": 0.778,
      "rewards/accuracies": 0.4937500059604645,
      "rewards/chosen": 0.8641214370727539,
      "rewards/margins": -0.04654361680150032,
      "rewards/rejected": 0.9106650352478027,
      "step": 680
    },
    {
      "epoch": 2.300500834724541,
      "grad_norm": 27234.771484375,
      "learning_rate": 1.153846153846154e-06,
      "logits/chosen": -1.1878981590270996,
      "logits/rejected": -1.116245150566101,
      "logps/chosen": -91.92864227294922,
      "logps/rejected": -97.61470031738281,
      "loss": 0.7628,
      "rewards/accuracies": 0.453125,
      "rewards/chosen": 0.8921268582344055,
      "rewards/margins": -0.021655883640050888,
      "rewards/rejected": 0.9137827157974243,
      "step": 690
    },
    {
      "epoch": 2.333889816360601,
      "grad_norm": 29758.02734375,
      "learning_rate": 1.0981047937569678e-06,
      "logits/chosen": -1.241631269454956,
      "logits/rejected": -1.3079473972320557,
      "logps/chosen": -95.13607025146484,
      "logps/rejected": -94.93540954589844,
      "loss": 0.7259,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 0.9068535566329956,
      "rewards/margins": 0.04922854155302048,
      "rewards/rejected": 0.8576251864433289,
      "step": 700
    },
    {
      "epoch": 2.333889816360601,
      "eval_logits/chosen": -2.6033453941345215,
      "eval_logits/rejected": -2.6160130500793457,
      "eval_logps/chosen": -70.01282501220703,
      "eval_logps/rejected": -71.83589172363281,
      "eval_loss": 0.7476304769515991,
      "eval_rewards/accuracies": 0.48076921701431274,
      "eval_rewards/chosen": 0.6883302330970764,
      "eval_rewards/margins": -0.026361653581261635,
      "eval_rewards/rejected": 0.7146918773651123,
      "eval_runtime": 9.2436,
      "eval_samples_per_second": 10.818,
      "eval_steps_per_second": 1.406,
      "step": 700
    },
    {
      "epoch": 2.367278797996661,
      "grad_norm": 43604.1484375,
      "learning_rate": 1.0423634336677815e-06,
      "logits/chosen": -1.2319291830062866,
      "logits/rejected": -1.0833606719970703,
      "logps/chosen": -101.17703247070312,
      "logps/rejected": -101.57230377197266,
      "loss": 0.7447,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.9884071350097656,
      "rewards/margins": 0.02487456426024437,
      "rewards/rejected": 0.9635327458381653,
      "step": 710
    },
    {
      "epoch": 2.4006677796327214,
      "grad_norm": 30523.728515625,
      "learning_rate": 9.866220735785954e-07,
      "logits/chosen": -1.2015352249145508,
      "logits/rejected": -1.1423417329788208,
      "logps/chosen": -91.96528625488281,
      "logps/rejected": -94.86564636230469,
      "loss": 0.7541,
      "rewards/accuracies": 0.518750011920929,
      "rewards/chosen": 0.8548126220703125,
      "rewards/margins": -0.016587769612669945,
      "rewards/rejected": 0.8714004755020142,
      "step": 720
    },
    {
      "epoch": 2.4340567612687813,
      "grad_norm": 20972.287109375,
      "learning_rate": 9.308807134894092e-07,
      "logits/chosen": -1.3155931234359741,
      "logits/rejected": -1.2395012378692627,
      "logps/chosen": -95.99803924560547,
      "logps/rejected": -93.47974395751953,
      "loss": 0.7271,
      "rewards/accuracies": 0.5218750238418579,
      "rewards/chosen": 0.903459906578064,
      "rewards/margins": 0.03714854270219803,
      "rewards/rejected": 0.8663114309310913,
      "step": 730
    },
    {
      "epoch": 2.4674457429048413,
      "grad_norm": 23731.70703125,
      "learning_rate": 8.751393534002231e-07,
      "logits/chosen": -1.2311381101608276,
      "logits/rejected": -1.2720873355865479,
      "logps/chosen": -94.7515640258789,
      "logps/rejected": -96.54251861572266,
      "loss": 0.7315,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.8992401361465454,
      "rewards/margins": 0.046998530626297,
      "rewards/rejected": 0.8522415161132812,
      "step": 740
    },
    {
      "epoch": 2.5008347245409013,
      "grad_norm": 30966.607421875,
      "learning_rate": 8.193979933110368e-07,
      "logits/chosen": -1.134056568145752,
      "logits/rejected": -0.9202443957328796,
      "logps/chosen": -99.72076416015625,
      "logps/rejected": -98.74275207519531,
      "loss": 0.8108,
      "rewards/accuracies": 0.484375,
      "rewards/chosen": 0.9639767408370972,
      "rewards/margins": -0.06290479004383087,
      "rewards/rejected": 1.0268816947937012,
      "step": 750
    },
    {
      "epoch": 2.5008347245409013,
      "eval_logits/chosen": -2.6074583530426025,
      "eval_logits/rejected": -2.620072364807129,
      "eval_logps/chosen": -70.07588195800781,
      "eval_logps/rejected": -71.90266418457031,
      "eval_loss": 0.7470070123672485,
      "eval_rewards/accuracies": 0.48076921701431274,
      "eval_rewards/chosen": 0.6820242404937744,
      "eval_rewards/margins": -0.02599097043275833,
      "eval_rewards/rejected": 0.7080153226852417,
      "eval_runtime": 9.2714,
      "eval_samples_per_second": 10.786,
      "eval_steps_per_second": 1.402,
      "step": 750
    },
    {
      "epoch": 2.5342237061769617,
      "grad_norm": 26752.53515625,
      "learning_rate": 7.636566332218506e-07,
      "logits/chosen": -1.013121247291565,
      "logits/rejected": -1.0816230773925781,
      "logps/chosen": -92.10179138183594,
      "logps/rejected": -94.85665130615234,
      "loss": 0.7423,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.871351420879364,
      "rewards/margins": 0.012003597803413868,
      "rewards/rejected": 0.8593478202819824,
      "step": 760
    },
    {
      "epoch": 2.5676126878130217,
      "grad_norm": 25575.494140625,
      "learning_rate": 7.079152731326646e-07,
      "logits/chosen": -1.297263264656067,
      "logits/rejected": -1.2423512935638428,
      "logps/chosen": -91.28827667236328,
      "logps/rejected": -90.13557434082031,
      "loss": 0.7352,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 0.8331421613693237,
      "rewards/margins": 0.0030489694327116013,
      "rewards/rejected": 0.8300932049751282,
      "step": 770
    },
    {
      "epoch": 2.601001669449082,
      "grad_norm": 22674.587890625,
      "learning_rate": 6.521739130434783e-07,
      "logits/chosen": -1.1468771696090698,
      "logits/rejected": -1.3444620370864868,
      "logps/chosen": -96.02565002441406,
      "logps/rejected": -88.688720703125,
      "loss": 0.6977,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 0.9214933514595032,
      "rewards/margins": 0.11876089870929718,
      "rewards/rejected": 0.8027324676513672,
      "step": 780
    },
    {
      "epoch": 2.634390651085142,
      "grad_norm": 25059.966796875,
      "learning_rate": 5.964325529542921e-07,
      "logits/chosen": -1.2767564058303833,
      "logits/rejected": -1.5044667720794678,
      "logps/chosen": -93.58012390136719,
      "logps/rejected": -89.54638671875,
      "loss": 0.7096,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 0.9088797569274902,
      "rewards/margins": 0.08423643559217453,
      "rewards/rejected": 0.8246432542800903,
      "step": 790
    },
    {
      "epoch": 2.667779632721202,
      "grad_norm": 24861.14453125,
      "learning_rate": 5.40691192865106e-07,
      "logits/chosen": -1.176232099533081,
      "logits/rejected": -1.2009626626968384,
      "logps/chosen": -93.93013000488281,
      "logps/rejected": -99.1001968383789,
      "loss": 0.7724,
      "rewards/accuracies": 0.45625001192092896,
      "rewards/chosen": 0.8938418626785278,
      "rewards/margins": -0.0519951656460762,
      "rewards/rejected": 0.9458369016647339,
      "step": 800
    },
    {
      "epoch": 2.667779632721202,
      "eval_logits/chosen": -2.61333966255188,
      "eval_logits/rejected": -2.6259729862213135,
      "eval_logps/chosen": -70.12263488769531,
      "eval_logps/rejected": -71.950927734375,
      "eval_loss": 0.7465523481369019,
      "eval_rewards/accuracies": 0.48076921701431274,
      "eval_rewards/chosen": 0.6773492097854614,
      "eval_rewards/margins": -0.025838693603873253,
      "eval_rewards/rejected": 0.703187882900238,
      "eval_runtime": 9.2403,
      "eval_samples_per_second": 10.822,
      "eval_steps_per_second": 1.407,
      "step": 800
    },
    {
      "epoch": 2.701168614357262,
      "grad_norm": 26845.5546875,
      "learning_rate": 4.849498327759198e-07,
      "logits/chosen": -1.30864417552948,
      "logits/rejected": -1.1018791198730469,
      "logps/chosen": -92.08133697509766,
      "logps/rejected": -95.78357696533203,
      "loss": 0.7604,
      "rewards/accuracies": 0.48124998807907104,
      "rewards/chosen": 0.8178603053092957,
      "rewards/margins": -0.02892393432557583,
      "rewards/rejected": 0.8467842936515808,
      "step": 810
    },
    {
      "epoch": 2.734557595993322,
      "grad_norm": 25556.12890625,
      "learning_rate": 4.292084726867336e-07,
      "logits/chosen": -1.3646066188812256,
      "logits/rejected": -1.4354004859924316,
      "logps/chosen": -91.73075103759766,
      "logps/rejected": -90.8874740600586,
      "loss": 0.7698,
      "rewards/accuracies": 0.4625000059604645,
      "rewards/chosen": 0.8087564706802368,
      "rewards/margins": -0.06598453223705292,
      "rewards/rejected": 0.8747409582138062,
      "step": 820
    },
    {
      "epoch": 2.7679465776293823,
      "grad_norm": 27161.7890625,
      "learning_rate": 3.734671125975474e-07,
      "logits/chosen": -0.9889456033706665,
      "logits/rejected": -1.152662992477417,
      "logps/chosen": -103.38450622558594,
      "logps/rejected": -101.4161605834961,
      "loss": 0.7234,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": 1.0016874074935913,
      "rewards/margins": 0.0738920122385025,
      "rewards/rejected": 0.92779541015625,
      "step": 830
    },
    {
      "epoch": 2.8013355592654423,
      "grad_norm": 21366.80859375,
      "learning_rate": 3.1772575250836125e-07,
      "logits/chosen": -1.2567417621612549,
      "logits/rejected": -1.3650658130645752,
      "logps/chosen": -93.31244659423828,
      "logps/rejected": -92.9177017211914,
      "loss": 0.7573,
      "rewards/accuracies": 0.48124998807907104,
      "rewards/chosen": 0.8482160568237305,
      "rewards/margins": -0.01922004483640194,
      "rewards/rejected": 0.8674361109733582,
      "step": 840
    },
    {
      "epoch": 2.8347245409015027,
      "grad_norm": 23125.5625,
      "learning_rate": 2.619843924191751e-07,
      "logits/chosen": -1.262324571609497,
      "logits/rejected": -1.1542106866836548,
      "logps/chosen": -94.78192901611328,
      "logps/rejected": -96.29552459716797,
      "loss": 0.7955,
      "rewards/accuracies": 0.40937501192092896,
      "rewards/chosen": 0.8345166444778442,
      "rewards/margins": -0.08705161511898041,
      "rewards/rejected": 0.9215682744979858,
      "step": 850
    },
    {
      "epoch": 2.8347245409015027,
      "eval_logits/chosen": -2.6155214309692383,
      "eval_logits/rejected": -2.628143310546875,
      "eval_logps/chosen": -70.14826202392578,
      "eval_logps/rejected": -71.97748565673828,
      "eval_loss": 0.7462476491928101,
      "eval_rewards/accuracies": 0.48076921701431274,
      "eval_rewards/chosen": 0.6747880578041077,
      "eval_rewards/margins": -0.025744078680872917,
      "eval_rewards/rejected": 0.7005321979522705,
      "eval_runtime": 9.2505,
      "eval_samples_per_second": 10.81,
      "eval_steps_per_second": 1.405,
      "step": 850
    },
    {
      "epoch": 2.8681135225375627,
      "grad_norm": 25030.73828125,
      "learning_rate": 2.0624303232998886e-07,
      "logits/chosen": -1.1980535984039307,
      "logits/rejected": -1.1581947803497314,
      "logps/chosen": -99.4047622680664,
      "logps/rejected": -95.48924255371094,
      "loss": 0.7647,
      "rewards/accuracies": 0.4937500059604645,
      "rewards/chosen": 0.8572729825973511,
      "rewards/margins": -0.026553843170404434,
      "rewards/rejected": 0.8838268518447876,
      "step": 860
    },
    {
      "epoch": 2.9015025041736227,
      "grad_norm": 18634.662109375,
      "learning_rate": 1.505016722408027e-07,
      "logits/chosen": -0.8372812271118164,
      "logits/rejected": -1.0016781091690063,
      "logps/chosen": -101.34564971923828,
      "logps/rejected": -101.27140045166016,
      "loss": 0.727,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 1.01093327999115,
      "rewards/margins": 0.032012131065130234,
      "rewards/rejected": 0.9789212942123413,
      "step": 870
    },
    {
      "epoch": 2.9348914858096826,
      "grad_norm": 24031.904296875,
      "learning_rate": 9.47603121516165e-08,
      "logits/chosen": -1.2507727146148682,
      "logits/rejected": -1.1163171529769897,
      "logps/chosen": -98.29618072509766,
      "logps/rejected": -93.54643249511719,
      "loss": 0.7537,
      "rewards/accuracies": 0.503125011920929,
      "rewards/chosen": 0.902213454246521,
      "rewards/margins": 0.007136552128940821,
      "rewards/rejected": 0.8950770497322083,
      "step": 880
    },
    {
      "epoch": 2.968280467445743,
      "grad_norm": 24032.09375,
      "learning_rate": 3.901895206243033e-08,
      "logits/chosen": -0.9983285665512085,
      "logits/rejected": -1.0935609340667725,
      "logps/chosen": -96.77687072753906,
      "logps/rejected": -97.1585693359375,
      "loss": 0.764,
      "rewards/accuracies": 0.4906249940395355,
      "rewards/chosen": 0.9274862408638,
      "rewards/margins": -0.02620454505085945,
      "rewards/rejected": 0.9536908268928528,
      "step": 890
    }
  ],
  "logging_steps": 10,
  "max_steps": 897,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
